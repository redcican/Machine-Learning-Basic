{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05 Save and Restore models.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/redcican/Machine-Learning-Basic/blob/master/05_Save_and_Restore_models.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "tqsFlJGjvC7R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Model progress can be saved during - and after - training. This means a model can resume where it left off and avoid long training times. Saving also means you can share your model and others can recreate your work.\n",
        "\n",
        "#### Options\n",
        "\n",
        "There are different ways to save TensorFlow models - depending on the API you are using. This guid uses tf.keras."
      ]
    },
    {
      "metadata": {
        "id": "gYYf0y7zu8OY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q h5py pyyaml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hd1VBlN6vmcP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "76eac911-bc82-4b22-f668-f3e8da75918f"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FPJ--bB1woS6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Get an example dataset"
      ]
    },
    {
      "metadata": {
        "id": "Na0gMp-jv0Pv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "74ce8259-25c0-4157-90ef-cd84af2c0c31"
      },
      "cell_type": "code",
      "source": [
        "(train_images, train_labels),(test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_labels = train_labels[:1000]\n",
        "test_labels = test_labels[:1000]\n",
        "\n",
        "train_images = train_images[:1000].reshape(-1, 28*28) / 255.0\n",
        "test_images = test_images[:1000].reshape(-1, 28*28) / 255.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iO9gNCnEwrBZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##  2. Define a model"
      ]
    },
    {
      "metadata": {
        "id": "P__Bo0NHwlQe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "2d16cdd4-96f0-49a9-fd96-a8c8ac77b818"
      },
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(784,)),\n",
        "        keras.layers.Dropout(0.2),\n",
        "        keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "    ])\n",
        "    \n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                 loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "                 metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EGDwDXNCxPkv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Save Checkpoints during training\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "The primary use case is to automatically save checkpoints during and at the end of training. This way you can use a trained model without having to retrain it, or pick-up training where you left of - in case the training process was interrupted.\n",
        "\n",
        "`tf.keras.callbacks.ModelCheckpoint` is a callback that performs this task. The callback takes a couple of argument to configure checkpointing.\n",
        "\n",
        "\n",
        "### 3.1 Checkpoint callback usage"
      ]
    },
    {
      "metadata": {
        "id": "Q3OaGuVhxL-o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "2a7e829a-c221-4d74-d735-3082de3bada6"
      },
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"training_1/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create checkpoint callback\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                verbose=1)\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=10,\n",
        "         validation_data = (test_images,test_labels),\n",
        "         callbacks=[cp_callback])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples, validate on 1000 samples\n",
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 1.1620 - acc: 0.6670 - val_loss: 0.6813 - val_acc: 0.8070\n",
            "\n",
            "Epoch 00001: saving model to training_1/cp.ckpt\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 0s 200us/step - loss: 0.4189 - acc: 0.8850 - val_loss: 0.5106 - val_acc: 0.8340\n",
            "\n",
            "Epoch 00002: saving model to training_1/cp.ckpt\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 0s 197us/step - loss: 0.2845 - acc: 0.9290 - val_loss: 0.4774 - val_acc: 0.8450\n",
            "\n",
            "Epoch 00003: saving model to training_1/cp.ckpt\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 0s 207us/step - loss: 0.2088 - acc: 0.9470 - val_loss: 0.4714 - val_acc: 0.8480\n",
            "\n",
            "Epoch 00004: saving model to training_1/cp.ckpt\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 0s 196us/step - loss: 0.1502 - acc: 0.9660 - val_loss: 0.4414 - val_acc: 0.8490\n",
            "\n",
            "Epoch 00005: saving model to training_1/cp.ckpt\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 0s 198us/step - loss: 0.1077 - acc: 0.9850 - val_loss: 0.4183 - val_acc: 0.8580\n",
            "\n",
            "Epoch 00006: saving model to training_1/cp.ckpt\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 0s 220us/step - loss: 0.0796 - acc: 0.9850 - val_loss: 0.4073 - val_acc: 0.8710\n",
            "\n",
            "Epoch 00007: saving model to training_1/cp.ckpt\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 0s 202us/step - loss: 0.0668 - acc: 0.9960 - val_loss: 0.4012 - val_acc: 0.8720\n",
            "\n",
            "Epoch 00008: saving model to training_1/cp.ckpt\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 0s 197us/step - loss: 0.0553 - acc: 0.9940 - val_loss: 0.4207 - val_acc: 0.8540\n",
            "\n",
            "Epoch 00009: saving model to training_1/cp.ckpt\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 0s 202us/step - loss: 0.0362 - acc: 1.0000 - val_loss: 0.4058 - val_acc: 0.8650\n",
            "\n",
            "Epoch 00010: saving model to training_1/cp.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f70e9fb1278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "erWS3q6VyRd_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17c13670-5daf-424b-8e11-10cbe83a797f"
      },
      "cell_type": "code",
      "source": [
        "!ls {checkpoint_dir}"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint  cp.ckpt.data-00000-of-00001  cp.ckpt.index\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "81qQzv_lhIez",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create a new, untrained model. When restoring a model from only weights, you must have a model with the same architecture as the original model. Since it's the same model architecture, we can share weights despite that it's a different instance of the model.\n",
        "\n",
        "Now rebuild a fresh, untrained model, and evaluate it on the test set. An untrained model will perform at chance levels (~ 10% accuracy)"
      ]
    },
    {
      "metadata": {
        "id": "ZgputQzJhDwY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "3ffffb8e-e75d-4a3f-da1c-9eb22b54b154"
      },
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "\n",
        "loss, acc = model.evaluate(test_images, test_labels)\n",
        "print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 0s 129us/step\n",
            "Untrained model, accuracy:  9.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J-E5R6ZFhxAJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Then load the weights from the checkpoint, and re-evaluate"
      ]
    },
    {
      "metadata": {
        "id": "I8UPV5FZhvjB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b8f76a05-3b33-4e91-db6f-40a3a2c3ba28"
      },
      "cell_type": "code",
      "source": [
        "model.load_weights(checkpoint_path)\n",
        "\n",
        "loss, acc = model.evaluate(test_images, test_labels)\n",
        "print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 0s 48us/step\n",
            "Untrained model, accuracy: 86.50%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "syD3gG17iCoA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.2 Checkpoint callback options"
      ]
    },
    {
      "metadata": {
        "id": "buOKQktIiF5I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The callback provides several options to give the resulting checkpoints unqiue names, and adjust the checkpointing frequency.\n",
        "\n",
        "Train a new model, and save uniquely named checkpoints once every 5-epochs."
      ]
    },
    {
      "metadata": {
        "id": "6kur5Kz1h-hj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "8caca691-5c60-461f-a553-66d27be2efc7"
      },
      "cell_type": "code",
      "source": [
        "# include the epoch in the file name. (uses 'str.format')\n",
        "\n",
        "checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    checkpoint_path, verbose=1, save_weights_only=True,\n",
        "    # save weights, every 5-epochs\n",
        "    period = 5\n",
        ")\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "model.fit(train_images, train_labels,\n",
        "         epochs=50, callbacks=[cp_callback],\n",
        "         validation_data = (test_images, test_labels),\n",
        "         verbose=0)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00005: saving model to training_2/cp-0005.ckpt\n",
            "\n",
            "Epoch 00010: saving model to training_2/cp-0010.ckpt\n",
            "\n",
            "Epoch 00015: saving model to training_2/cp-0015.ckpt\n",
            "\n",
            "Epoch 00020: saving model to training_2/cp-0020.ckpt\n",
            "\n",
            "Epoch 00025: saving model to training_2/cp-0025.ckpt\n",
            "\n",
            "Epoch 00030: saving model to training_2/cp-0030.ckpt\n",
            "\n",
            "Epoch 00035: saving model to training_2/cp-0035.ckpt\n",
            "\n",
            "Epoch 00040: saving model to training_2/cp-0040.ckpt\n",
            "\n",
            "Epoch 00045: saving model to training_2/cp-0045.ckpt\n",
            "\n",
            "Epoch 00050: saving model to training_2/cp-0050.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f713095bb38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "H3DhlFuEi5St",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "c851c7fd-7b8d-4812-dd68-ee25dad25ea5"
      },
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "\n",
        "# Sort the checkpoints by modificaiton time\n",
        "checkpoints = pathlib.Path(checkpoint_dir).glob(\"*.index\")\n",
        "checkpoints = sorted(checkpoints, key=lambda cp:cp.stat().st_mtime)\n",
        "checkpoints = [cp.with_suffix('') for cp in checkpoints]\n",
        "latest = str(checkpoints[-1])\n",
        "checkpoints"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('training_2/cp-0030.ckpt'),\n",
              " PosixPath('training_2/cp-0035.ckpt'),\n",
              " PosixPath('training_2/cp-0040.ckpt'),\n",
              " PosixPath('training_2/cp-0045.ckpt'),\n",
              " PosixPath('training_2/cp-0050.ckpt')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "NbEhTfImlQp1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "986f2f33-9ff2-4c09-a280-eb90c8d97bd9"
      },
      "cell_type": "code",
      "source": [
        "latest"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'training_2/cp-0050.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "xP-E5YSbkiOU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "61b83f52-db32-4ba7-a268-a88bf63bd7df"
      },
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "model.load_weights(latest)\n",
        "loss, acc = model.evaluate(test_images,test_labels)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 0s 113us/step\n",
            "Restored model, accuracy: 87.50%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XFVxsI9slJNo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.3 What are these files?"
      ]
    },
    {
      "metadata": {
        "id": "r4fyIq2KlLl1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The above code stores the weights to a collection of checkpoint-formatted files that contains only the trained weights in a binary format. Checkpoints contain: * One or more shards that contain your model's weights. * An index file that indicates which weights are stored in a which shard."
      ]
    },
    {
      "metadata": {
        "id": "XuWop6R3l7S_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.4 Manually save weights"
      ]
    },
    {
      "metadata": {
        "id": "Gue3h3eik_0R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "32a9c6f9-1c04-44f8-975d-b85071190293"
      },
      "cell_type": "code",
      "source": [
        "# save the weights\n",
        "model.save_weights('./checkpoints/my_checkpoint')\n",
        "\n",
        "# Restore the weights\n",
        "model = create_model()\n",
        "model.load_weights('./checkpoints/my_checkpoint')\n",
        "\n",
        "loss,acc = model.evaluate(test_images, test_labels)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 0s 129us/step\n",
            "Restored model, accuracy: 87.50%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bHNDawT9mbgy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.5 Save the entire model\n",
        "\n",
        "The entire model can be saved to a file that contains the weight values, the model's configuration, and even the optimizer's configuration. This allow you to checkpoint a model and resume training later - from the exact same state - without access to the original code.\n",
        "\n",
        "Keras provides a basic save format using the HDF5 standard. For our purpose, the saved model can be treated as a single binar blob."
      ]
    },
    {
      "metadata": {
        "id": "3woQNoWvmXth",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "2d81ac7c-1d6d-4f54-e8fa-816bd30f7ad3"
      },
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "\n",
        "model.fit(train_images, train_labels, epochs = 5)\n",
        "\n",
        "model.save('my_model.h5')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1000/1000 [==============================] - 0s 447us/step - loss: 1.2173 - acc: 0.6280\n",
            "Epoch 2/5\n",
            "1000/1000 [==============================] - 0s 142us/step - loss: 0.4313 - acc: 0.8820\n",
            "Epoch 3/5\n",
            "1000/1000 [==============================] - 0s 158us/step - loss: 0.2886 - acc: 0.9300\n",
            "Epoch 4/5\n",
            "1000/1000 [==============================] - 0s 146us/step - loss: 0.1986 - acc: 0.9590\n",
            "Epoch 5/5\n",
            "1000/1000 [==============================] - 0s 146us/step - loss: 0.1576 - acc: 0.9660\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M793lL9Om9bL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "703cca24-f1b2-4522-fabc-bd9b0d04c19c"
      },
      "cell_type": "code",
      "source": [
        "# Create the model from that file\n",
        "\n",
        "new_model = keras.models.load_model('my_model.h5')\n",
        "new_model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_20 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eAU9P8STnFwZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "9a4b0fbd-0044-44be-b533-c95c3e24b440"
      },
      "cell_type": "code",
      "source": [
        "loss, acc = new_model.evaluate(test_images, test_labels)\n",
        "print(\"Restored model, accuracy: {:5.2f}\".format(100*acc))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 0s 176us/step\n",
            "Restored model, accuracy: 85.50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1zhwGc0anSe4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This technique saves everything:\n",
        "\n",
        "* The weight value\n",
        "\n",
        "* The model's configuration (architecture)\n",
        "\n",
        "* The optimizer configuration\n",
        "\n",
        "Keras saves models by inspecting the architeture. Currently, it is not able to save TensorFlow optimizers (from tf.traiin). When using those you will need to re-compile the model after loading, and you will loss the state of the optimizer."
      ]
    },
    {
      "metadata": {
        "id": "BgkGG5l2nON3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}